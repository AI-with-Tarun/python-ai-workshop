{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Search RAG"
      ],
      "metadata": {
        "id": "d4Uy-O1uEW6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data - Chunk - Embeddings (Dense and Sparse) - Vector Database\n",
        "* Instead of using Langchain directly, we will use Qdrant or vector database."
      ],
      "metadata": {
        "id": "T0UULQAwEoAi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPRjLTrE4A-C"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community\n",
        "!pip install pypdfium2\n",
        "!pip install fastembed\n",
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader,PyPDFium2Loader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXa0Xevl4KkW",
        "outputId": "278b4aa8-f3eb-48f9-e53f-44cef93dc69f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://atyantik.com/\",\n",
        "    \"https://atyantik.com/about-us/\",\n",
        "    \"https://atyantik.com/software-development-company/\",\n",
        "    \"https://atyantik.com/saas-development/\",\n",
        "]"
      ],
      "metadata": {
        "id": "Q4_5JLtS4Po5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(urls)\n",
        "# loader = PyPDF(/content/drive/MyDrive/Resume/Tarun_Resume.pdf)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "-hvaVeMV4OX6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=0)\n",
        "chunks = splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "X8lhv3LL4RI7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va8H8haTFO1L",
        "outputId": "c2d64e41-d156-47e1-b82a-f588a8c98070"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Database"
      ],
      "metadata": {
        "id": "720hRp994V6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient,models\n",
        "from qdrant_client.http.models import Distance, VectorParams, SparseVectorParams\n",
        "from qdrant_client.models import PointStruct\n",
        "from fastembed import TextEmbedding, SparseTextEmbedding\n",
        "# search logic (Points)\n",
        "# vectorParams - Dense\n",
        "# Distance - Cosine\n",
        "# SparseParams: TFIDF, BM25 and BM42\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "WsreiX3SFs59"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the client\n",
        "2. Create collection: Configure parameters\n",
        "3. Add documents. Loop it over the entire chunks with the embeddings.\n",
        "4. Search (Points)\n",
        "5. Node: LangGraph node for the retrieval."
      ],
      "metadata": {
        "id": "VswmpFdKGrIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = userdata.get(\"QDRANT_URL\")\n",
        "api_key = userdata.get(\"QDRANT_API_KEY\")"
      ],
      "metadata": {
        "id": "bIbL4ivmHivn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = QdrantClient(\n",
        "    url = url,\n",
        "    api_key=api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "DUu9v-jF4UtZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"hybrid\""
      ],
      "metadata": {
        "id": "gwz2FWNr95DD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the embedding model"
      ],
      "metadata": {
        "id": "kZvUgrsUHxLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-base-en\")"
      ],
      "metadata": {
        "id": "5G7I2llJHsb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_embedding_model = SparseTextEmbedding(\"Qdrant/BM25\")"
      ],
      "metadata": {
        "id": "SOH4ahw1H_C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.create_collection(\n",
        "    collection_name = collection_name,\n",
        "    vectors_config = {\n",
        "        \"dense\": VectorParams(\n",
        "            size = 768,\n",
        "            distance = Distance.COSINE,\n",
        "            on_disk=True\n",
        "        )\n",
        "    },\n",
        "    sparse_vectors_config = {\n",
        "        \"sparse\": SparseVectorParams(\n",
        "            modifier=models.Modifier.IDF\n",
        "        )\n",
        "    },\n",
        "    quantization_config=models.BinaryQuantization(\n",
        "        binary = models.BinaryQuantizationConfig(always_ram=False)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz-N6ATnK0oP",
        "outputId": "3c61f854-7ab4-4138-e1eb-9c87d2992b0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Points - Add your data. Upsert: Updating it into the collection"
      ],
      "metadata": {
        "id": "ONWPlsWbM87b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_eles = ['Naruto','OP','DBZ','Bleach']"
      ],
      "metadata": {
        "id": "Ot4fImYZN8UO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, ele in enumerate(dummy_eles):\n",
        "  print(ele)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOrteGi0N3UK",
        "outputId": "ff17debb-39e2-4749-cfad-fc23d5922bfb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naruto\n",
            "OP\n",
            "DBZ\n",
            "Bleach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "enumerate - looping but with an index"
      ],
      "metadata": {
        "id": "BJ8fKjeOOm6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "client\n",
        "  - payload\n",
        "  - vector (embeddings)\n",
        "  - id - unique"
      ],
      "metadata": {
        "id": "apWhVkyEOJvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_embeddings = list(dense_embedding_model.embed(doc.page_content for doc in chunks))\n",
        "sparse_embeddings = list(sparse_embedding_model.embed(doc.page_content for doc in chunks))"
      ],
      "metadata": {
        "id": "rjcugONgOzWX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points = []\n",
        "\n",
        "for idx in range(len(chunks)):\n",
        "    point = PointStruct(\n",
        "        id = idx,\n",
        "        vector = {\n",
        "            \"dense\": dense_embeddings[idx],\n",
        "            \"sparse\": sparse_embeddings[idx].as_object()\n",
        "        },\n",
        "        payload = {\"document\": chunks[idx].page_content,\n",
        "                   \"source\": chunks[idx].metadata['source']}\n",
        "    )\n",
        "    points.append(point)"
      ],
      "metadata": {
        "id": "oxcUEbq8NeZ4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add = client.upsert(\n",
        "    points = points,\n",
        "    collection_name = collection_name\n",
        ")"
      ],
      "metadata": {
        "id": "9bvIDqGkLAfW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Enumerate: If you need index along with sequence/elements\n",
        "- Zip: When you have multiple lists of same length, if you want to loop through all the list, then you use zip\n",
        "- next: use only when you have a return object as Iterable"
      ],
      "metadata": {
        "id": "fI-1sK9eUDii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query"
      ],
      "metadata": {
        "id": "I8uCCQsLTeIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"mail to contact Atyantik\""
      ],
      "metadata": {
        "id": "3y7j1WXDTfBl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_vectors = next(dense_embedding_model.query_embed(query))\n",
        "sparse_vectors = next(sparse_embedding_model.query_embed(query))"
      ],
      "metadata": {
        "id": "gsgi5XX4Th7x"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefetch = [\n",
        "    models.Prefetch(\n",
        "        query = dense_vectors,\n",
        "        using = \"dense\", # vector search\n",
        "        limit = 10\n",
        "    ),\n",
        "    models.Prefetch(\n",
        "        query = models.SparseVector(**sparse_vectors.as_object()),\n",
        "        using = \"sparse\", # keyword search\n",
        "        limit = 10\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "1nps6Yf-UVHi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3"
      ],
      "metadata": {
        "id": "cTw_9g7AWEXH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = client.query_points(\n",
        "    collection_name = collection_name,\n",
        "    prefetch = prefetch, # hybrid search\n",
        "    query = dense_vectors,\n",
        "    using = \"dense\",\n",
        "    with_payload=True,\n",
        "    limit = top_k\n",
        ")"
      ],
      "metadata": {
        "id": "FBjSkm5cVrGb"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context.points[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9WA4NdWjHm",
        "outputId": "b92690ef-311e-434c-e6c6-9b4c2b9e7f8c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ScoredPoint(id=44, version=0, score=0.8297515, payload={'document': 'Atyantik is a team of techno enthusiasts with over a decade of experience delivering IT solutions for clients across diverse industries. At Atyantik, we believe in providing our customers a value-driven, highly professional expertise and offering much more up-to-date technology, time-efficient, and cost-effective solutions.\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSite map\\nAbout us\\nServices\\nOur Work\\nCareers\\n \\n\\nPartnership\\nContact\\n \\n\\nContact\\n\\n\\t\\t\\t\\t\\t\\t\\t501, Privilege Avenue, Dr. Vikram Sarabhai Campus, Atlantis Lane, Beside Tricolor Hospital, Above HDFC Bank, Vadodara, Gujarat 390022, India\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t+91-8347435435\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tcontact@atyantik.com\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\nCopyright Â© 2025 Atyantik Technologies Private Limited\\n\\n\\nPrivacy policy\\nTerms and Conditions\\nCookie policy', 'source': 'https://atyantik.com/saas-development/'}, vector=None, shard_key=None, order_value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph\n",
        "\n",
        "- context:List[str]\n",
        "- query: str\n",
        "- answer: str"
      ],
      "metadata": {
        "id": "MXUH2EkSXVAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search(state: RAGState) -> RAGState:\n",
        "  dense_vectors = next(dense_embedding_model.query_embed(state['query']))\n",
        "  sparse_vectors = next(sparse_embedding_model.query_embed(state['query']))\n",
        "  prefetch = [\n",
        "    models.Prefetch(\n",
        "        query = dense_vectors,\n",
        "        using = \"dense\", # vector search\n",
        "        limit = 10\n",
        "    ),\n",
        "    models.Prefetch(\n",
        "        query = models.SparseVector(**sparse_vectors.as_object()),\n",
        "        using = \"sparse\", # keyword search\n",
        "        limit = 10\n",
        "    )\n",
        "]\n",
        "relevant_docs = client.query_points(\n",
        "    collection_name = collection_name,\n",
        "    prefetch = prefetch, # hybrid search\n",
        "    query = dense_vectors,\n",
        "    using = \"dense\",\n",
        "    with_payload=True,\n",
        "    limit = top_k\n",
        ")\n",
        "context = []\n",
        "for info in relevant_docs.points:\n",
        "  context.append(info.payload['document'])\n",
        "\n",
        "state['context'] = context\n",
        "return state"
      ],
      "metadata": {
        "id": "hfpcU1U4XKpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}